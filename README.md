# Federated Learning, LLMs and Fairness

## 📖 Overview
This repository contains the research code, experiments, and documentation related to my **Master Thesis** on the intersection of **Federated Learning**, **Large Language Models (LLMs)**, and **Fairness**.  

The project investigates:
- How **federated learning frameworks** can be applied to train or adapt large language models without centralizing data.
- The **fairness implications** of distributed learning, including potential biases introduced by heterogeneous client data.
- Methods to **evaluate and mitigate bias** in LLMs trained or fine-tuned in a federated setup.

---

## 🧩 Objectives
- Explore federated learning paradigms (e.g., FedAvg, personalized FL) in the context of LLMs.  
- Define fairness metrics applicable to federated scenarios.  
- Analyze trade-offs between **performance, privacy, and fairness**.  
- Propose mitigation strategies to improve equitable outcomes across clients.  

---

## 📂 Repository Structure
- `notebooks/` – Jupyter/Colab notebooks for experiments and analyses.    
- `data/` – Scripts or loaders for datasets used in experiments 
- `results/` – Experimental results, logs, and evaluation metrics.  
- `docs/` – Thesis-related documentation and references.  

---

## 🛠️ Technologies
- **Python** (≥3.10)  
- **PyTorch** / **Transformers (Hugging Face)**  

---

## 🚀 Getting Started
1. Clone the repository:  
   ```bash
   git clone https://github.com/<your-username>/<repo-name>.git
   cd <repo-name>


## 📊 Evaluation
- The evaluation focuses on:

## 📜 License

## 👥 Contributors
- Leonardo Lei (Master’s Thesis Author)
- Supervisor(s) : Cinzia Cappiello, Mattia Sabella
- Collaborators
