# Federated Learning, LLMs and Fairness

## ğŸ“– Overview
This repository contains the research code, experiments, and documentation related to my **Master Thesis** on the intersection of **Federated Learning**, **Large Language Models (LLMs)**, and **Fairness**.  

The project investigates:
- How **federated learning frameworks** can be applied to train or adapt large language models without centralizing data.
- The **fairness implications** of distributed learning, including potential biases introduced by heterogeneous client data.
- Methods to **evaluate and mitigate bias** in LLMs trained or fine-tuned in a federated setup.

---

## ğŸ§© Objectives
- Explore federated learning paradigms (e.g., FedAvg, personalized FL) in the context of LLMs.  
- Define fairness metrics applicable to federated scenarios.  
- Analyze trade-offs between **performance, privacy, and fairness**.  
- Propose mitigation strategies to improve equitable outcomes across clients.  

---

## ğŸ“‚ Repository Structure
- `notebooks/` â€“ Jupyter/Colab notebooks for experiments and analyses.    
- `data/` â€“ Scripts or loaders for datasets used in experiments 
- `results/` â€“ Experimental results, logs, and evaluation metrics.  
- `docs/` â€“ Thesis-related documentation and references.  

---

## ğŸ› ï¸ Technologies
- **Python** (â‰¥3.10)  
- **PyTorch** / **Transformers (Hugging Face)**  

---

## ğŸš€ Getting Started
1. Clone the repository:  
   ```bash
   git clone https://github.com/<your-username>/<repo-name>.git
   cd <repo-name>


## ğŸ“Š Evaluation
- The evaluation focuses on:

## ğŸ“œ License

## ğŸ‘¥ Contributors
- Leonardo Lei (Masterâ€™s Thesis Author)
- Supervisor(s) : Cinzia Cappiello, Mattia Sabella
- Collaborators
